{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch as torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from kan import KAN, create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#literally copied the code below from the documentation.  Need to figure out what does what\n",
    "\n",
    "# Set the default data type to double\n",
    "torch.set_default_dtype(torch.float64)\n",
    "#set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_size = 20*20 # from 28*28\n",
    "\n",
    "'''\n",
    "initialize model\n",
    "- refer to MultKAN.py for more information\n",
    "    width: number of neurons in each layer, in order from input to output\n",
    "    k: order of the spline\n",
    "    seed: random seed\n",
    "    grid: grid intervals/grid points (affects the accuracy of the splines/learnable functions)\n",
    "'''\n",
    "model = KAN(width=[2, 5, 1], grid=5, k=3, seed=0, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "def read_idx_images(file_path):\n",
    "    \"\"\" Reads an IDX image file and returns a tensor of shape (N, 28, 28) \"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        f.read(4)  # Skip magic number\n",
    "        num_images = int.from_bytes(f.read(4), 'big')\n",
    "        rows = int.from_bytes(f.read(4), 'big')\n",
    "        cols = int.from_bytes(f.read(4), 'big')\n",
    "        data = np.frombuffer(f.read(), dtype=np.uint8).reshape(num_images, rows, cols)\n",
    "        images = torch.tensor(data, dtype=torch.float32)  # Convert to float\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(20), #change the size of the image to 20x20\n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "        resized_images = torch.stack([transform(image) for image in images])\n",
    "        return resized_images\n",
    "\n",
    "def read_idx_labels(file_path):\n",
    "    \"\"\" Reads an IDX label file and returns a tensor of shape (N,) \"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        f.read(4)  # Skip magic number\n",
    "        num_labels = int.from_bytes(f.read(4), 'big')\n",
    "        data = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        return torch.tensor(data, dtype=torch.long)  # Convert to long tensor\n",
    "\n",
    "class OurData:\n",
    "    def __init__(self):\n",
    "        self.ourdataset = {}\n",
    "        self.ourdataset['train_input'] = read_idx_images('/workspaces/KAN-Network/Dataset/t10k-images.idx3-ubyte') #contains the training data, each data is the binary representation of an image as per the MNIST dataset\n",
    "        self.ourdataset['test_input'] = read_idx_images('/workspaces/KAN-Network/Dataset/t10k-images.idx3-ubyte') #contains the testing data, same format as train_input\n",
    "        self.ourdataset['train_label'] = read_idx_labels('/workspaces/KAN-Network/Dataset/train-labels.idx1-ubyte') #contains the labels for the training data\n",
    "        self.ourdataset['test_label'] = read_idx_labels('/workspaces/KAN-Network/Dataset/t10k-labels.idx1-ubyte') #contains the labels for the testing data\n",
    "    def __getitem__(self, key):\n",
    "        return self.ourdataset[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from kan.utils import create_dataset\n",
    "# create dataset f(x,y) = exp(sin(pi*x)+y^2)\n",
    "f = lambda x: torch.exp(torch.sin(torch.pi*x[:,[0]]) + x[:,[1]]**2)\n",
    "dataset = create_dataset(f, n_var=2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Our dataset\n",
    "data = OurData()\n",
    "ourdata = {}\n",
    "ourdata['train_input'] = data['train_input'].view(-1, input_size)\n",
    "ourdata['train_label'] = data['train_label']\n",
    "ourdata['test_input'] = data['test_input'].view(-1, input_size)\n",
    "ourdata['test_label'] = data['test_label']\n",
    "\n",
    "model(ourdata['train_input']) #forward pass of the model\n",
    "model.plot() #plots the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#code to train the model\n",
    "'''\n",
    "Training the model off the dataset\n",
    "- opt: optimization method (LBFGS)\n",
    "- steps: training steps\n",
    "- lamb: penalty parameter\n",
    "other parameters: lr = learning rate = 1, loss_fn = loss function = None\n",
    "'''\n",
    "#fits the model to the dataset\n",
    "'''\n",
    "model.fit(ourdata, opt=\"LBFGS\", steps=50, lamb=0.001) #values from the basic example in the documentation\n",
    "model.plot() #plots the model\n",
    "\n",
    "model = model.prune()\n",
    "model.plot()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(ourdata.shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(dataset.shape())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
