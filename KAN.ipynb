{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from DataRead import OurData\n",
    "import traceback\n",
    "import struct\n",
    "\n",
    "from kan import KAN, create_dataset\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_size = 28*28 # from 28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_idx(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        zero, dtype, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for _ in range(dims))\n",
    "        return torch.tensor(np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)).to(torch.float32)\n",
    "    \n",
    "def compress(dataset, slice = 1):\n",
    "        fraction = int(784/slice)\n",
    "        arr = torch.tensor([])\n",
    "        for i in range(slice):\n",
    "            arr = torch.cat((arr, dataset[:, i*fraction:(i+1)*fraction].sum(dim=1, keepdim=True)), dim=1)\n",
    "        return arr\n",
    "\n",
    "class OurData:\n",
    "    def __init__(self):\n",
    "        self.ourdataset = {}\n",
    "        train_images = read_idx('/workspaces/KAN-Network/Dataset/train-images-idx3-ubyte/train-images-idx3-ubyte') #contains the training data, each data is the binary representation of an image as per the MNIST dataset\n",
    "        self.ourdataset['train_input'] = (train_images).view(-1, 28*28) #reshapes the data into a 2D array, each row is an image\n",
    "        test_images = read_idx('/workspaces/KAN-Network/Dataset/t10k-images-idx3-ubyte/t10k-images-idx3-ubyte') #contains the testing data, same format as train_input\n",
    "        self.ourdataset['test_input'] = (test_images).view(-1, 28*28) #reshapes the data into a 2D array, each row is an image\n",
    "        \n",
    "        #to-do: convert the lablels into 10 element arrays for classification\n",
    "        train_label = read_idx('/workspaces/KAN-Network/Dataset/train-labels-idx1-ubyte/train-labels-idx1-ubyte').unsqueeze(1) #contains the labels for the training data\n",
    "        test_label = read_idx('/workspaces/KAN-Network/Dataset/t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte').unsqueeze(1) #contains the labels for the testing data\n",
    "        self.ourdataset['train_label'] = torch.zeros(len(train_label), 10)\n",
    "        self.ourdataset['test_label'] = torch.zeros(len(test_label), 10)\n",
    "        #print(self.ourdataset['train_label'].size(), self.ourdataset['test_label'].size())\n",
    "        #the code below assigns a value of 1 to the correct labels in the 10 element array, everything else is 0\n",
    "        for i in range(len(train_label)):\n",
    "            self.ourdataset['train_label'][i][train_label[i].long()] = 1\n",
    "        for i in range(len(test_label)):\n",
    "            self.ourdataset['test_label'][i][test_label[i].long()] = 1\n",
    "        #print(\"These are our training inputs and labels\")\n",
    "    def __getitem__(self):\n",
    "        return self.ourdataset\n",
    "    def getitems(self, index, endindex = 10000, test = True):\n",
    "        key = 'test_input' if test else 'train_input'\n",
    "        key2 = 'test_label' if test else 'train_label'\n",
    "        return [self.ourdataset[key][index:endindex], self.ourdataset[key2][index:endindex]]\n",
    "    def filldata(self, m_ins, m_slices):\n",
    "        ourdatas = {}\n",
    "        for key in self.ourdataset:\n",
    "            thisdata = self.ourdataset[key]\n",
    "            isin = (key == 'train_input' or key == 'test_input')\n",
    "            ourdatas[key] = thisdata if (m_slices == 784) else compress(thisdata, m_slices)[:m_ins] if isin else thisdata[:m_ins] \n",
    "        return ourdatas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total train datapoints=60000, test datapoints=10000. approx time:1min/100 points model1, 30s/1000 points model2, 1min/2500 points model3\n",
    "data = OurData() #Our dataset\n",
    "ourdata = data.filldata(20, 784)\n",
    "ourdata2 = data.filldata(200, 112)\n",
    "ourdata3 = data.filldata(500, 28)\n",
    "#print(ourdata['train_input'].size(), ourdata2['train_input'].size(), ourdata3['train_input'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n",
      "checkpoint directory created: ./model2\n",
      "saving model version 0.0\n",
      "checkpoint directory created: ./model3\n",
      "saving model version 0.0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "initialize model\n",
    "- refer to MultKAN.py for more information\n",
    "    width: number of neurons in each layer, in order from input to output\n",
    "    k: order of the spline\n",
    "    seed: random seed\n",
    "    grid: grid intervals/grid points (affects the accuracy of the splines/learnable functions)\n",
    "'''\n",
    "model = KAN(width=[784, 10, 10], grid=5, k=3, seed=0, device=device)\n",
    "model2 = KAN(width=[112, 10, 10], grid=5, k=3, seed=0, device=device, ckpt_path='./model2')\n",
    "model3 = KAN(width=[28, 10, 10], grid=5, k=3, seed=0, device=device, ckpt_path='./model3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model(ourdata['train_input']) #forward pass of the model\n",
    "model2(ourdata2['train_input']) \n",
    "model3(ourdata3['train_input']) \n",
    "#print(\"model pass complete\")\n",
    "#model.plot() #plots the model, avoid doing this since it will plot functions for all the neurons(and we have a lot since we are dealing with images)\n",
    "\n",
    "#steps = intervals to divide the dataset and update model, epochs = how many times the entire dataset is passed through the model\n",
    "modelresults = []\n",
    "try:\n",
    "    modelresults.append(model.fit(ourdata, opt=\"LBFGS\", steps=25, lamb=0.001))\n",
    "    modelresults.append(model2.fit(ourdata2, opt=\"LBFGS\", steps=25, lamb=0.001))\n",
    "    modelresults.append(model3.fit(ourdata3, opt=\"LBFGS\", steps=25, lamb=0.001))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, len(modelresults[0]['train_loss']) + 1), modelresults[0]['train_loss'])\n",
    "plt.title('Model1 Train Loss')\n",
    "plt.show()\n",
    "plt.plot(range(1, len(modelresults[0]['test_loss']) + 1), modelresults[0]['test_loss'])\n",
    "plt.title('Model1 Test Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, len(modelresults[1]['train_loss']) + 1), modelresults[1]['train_loss'])\n",
    "plt.title('Model2 Train Loss')\n",
    "plt.show()\n",
    "plt.plot(range(1, len(modelresults[1]['test_loss']) + 1), modelresults[1]['test_loss'])\n",
    "plt.title('Model2 Test Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, len(modelresults[2]['train_loss']) + 1), modelresults[2]['train_loss'])\n",
    "plt.title('Model3 Train Loss')\n",
    "plt.show()\n",
    "plt.plot(range(1, len(modelresults[2]['test_loss']) + 1), modelresults[2]['test_loss'])\n",
    "plt.title('Model3 Test Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval1 = model.evaluate(ourdata)\n",
    "eval2 = model2.evaluate(ourdata2)\n",
    "eval3 = model3.evaluate(ourdata3)\n",
    "evaluation_results = [eval1, eval2, eval3]\n",
    "test_losses = [[result['test_loss'] for result in evaluation_results]]\n",
    "\n",
    "plt.scatter([i for i in range(1, 4)], test_losses, label='Test Loss')\n",
    "plt.xlabel('Model Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Scatter Plot of Models')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingdata = data.getitems(9950, 10000) \n",
    "predictions = model.forward(testingdata[0])\n",
    "predictions2 = model2.forward(compress(testingdata[0], 28))\n",
    "predictions3 = model3.forward(compress(testingdata[0], 3))\n",
    "allpredictions = [predictions, predictions2, predictions3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    plt.plot(range(len(allpredictions[i])), allpredictions[i].detach().numpy(), label=f'Model{i+1} Predictions')\n",
    "plt.plot(range(len(testingdata[1])), testingdata[1].detach().numpy(), label='Actual')\n",
    "plt.xlabel('Input Number')\n",
    "plt.ylabel('Output')\n",
    "plt.title('Model Predictions vs Actual')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = [0, 0, 0]\n",
    "correct = [0, 0, 0]\n",
    "for i in range(len(testingdata[1])):\n",
    "    print(i, testingdata[1][i].item(), end=\"\\t\")\n",
    "    for j in range(3):\n",
    "        print(j+1, allpredictions[j][i].item(), end=\"\\t\")\n",
    "        difference = abs(allpredictions[j][i].item()-i)\n",
    "        error[j] += difference\n",
    "    print()\n",
    "for j in range(3):\n",
    "    error[j] /= len(testingdata[1])\n",
    "    correct[j] = 100 - 100*(error[j] if error[j] < 1 else 1)\n",
    "\n",
    "plt.scatter([i for i in range(1, 4)], error, label='Average Error') \n",
    "plt.scatter([i for i in range(1, 4)], correct, label='Accuracy') \n",
    "plt.xlabel('Model Number')\n",
    "plt.title('Scatter Plot of Models')\n",
    "plt.legend()\n",
    "print(error)\n",
    "print(correct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a different method of calculating error, convert into a classification problem\n",
    "#figure out how to save and load models\n",
    "#experiment with parameters for better accuracy - grid, k, width/length, lamb, steps, lossfn, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
