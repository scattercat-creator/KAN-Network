{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from kan import KAN, create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    }
   ],
   "source": [
    "#literally copied the code below from the documentation.  Need to figure out what does what\n",
    "\n",
    "# Set the default data type to double\n",
    "torch.set_default_dtype(torch.float64)\n",
    "#set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_size = 20*20 # from 28*28\n",
    "\n",
    "'''\n",
    "initialize model\n",
    "- refer to MultKAN.py for more information\n",
    "    width: number of neurons in each layer, in order from input to output\n",
    "    k: order of the spline\n",
    "    seed: random seed\n",
    "    grid: grid intervals/grid points (affects the accuracy of the splines/learnable functions)\n",
    "'''\n",
    "model = KAN(width=[2, 5, 1], grid=5, k=3, seed=0, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torchvision.transforms as transforms doesn't work?\n",
    "def read_idx_images(file_path):\n",
    "    \"\"\" Reads an IDX image file and returns a tensor of shape (N, 28, 28) \"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        f.read(4)  # Skip magic number\n",
    "        num_images = int.from_bytes(f.read(4), 'big')\n",
    "        rows = int.from_bytes(f.read(4), 'big')\n",
    "        cols = int.from_bytes(f.read(4), 'big')\n",
    "        data = np.frombuffer(f.read(), dtype=np.uint8).reshape(num_images, rows, cols)\n",
    "        images = torch.tensor(data, dtype=torch.float32)  # Convert to float\n",
    "        return images\n",
    "        ''' \n",
    "        transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(20), #change the size of the image to 20x20\n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "        resized_images = torch.stack([transform(image) for image in images])\n",
    "        return resized_images'''\n",
    "\n",
    "def read_idx_labels(file_path):\n",
    "    \"\"\" Reads an IDX label file and returns a tensor of shape (N,) \"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        f.read(4)  # Skip magic number\n",
    "        num_labels = int.from_bytes(f.read(4), 'big')\n",
    "        data = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        return torch.tensor(data, dtype=torch.long)  # Convert to long tensor\n",
    "\n",
    "class OurData:\n",
    "    def __init__(self):\n",
    "        self.ourdataset = {}\n",
    "        self.ourdataset['train_input'] = read_idx_images('/workspaces/KAN-Network/Dataset/t10k-images.idx3-ubyte') #contains the training data, each data is the binary representation of an image as per the MNIST dataset\n",
    "        self.ourdataset['test_input'] = read_idx_images('/workspaces/KAN-Network/Dataset/t10k-images.idx3-ubyte') #contains the testing data, same format as train_input\n",
    "        self.ourdataset['train_label'] = read_idx_labels('/workspaces/KAN-Network/Dataset/train-labels.idx1-ubyte') #contains the labels for the training data\n",
    "        self.ourdataset['test_label'] = read_idx_labels('/workspaces/KAN-Network/Dataset/t10k-labels.idx1-ubyte') #contains the labels for the testing data\n",
    "    def __getitem__(self, key):\n",
    "        return self.ourdataset[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kan.utils import create_dataset\n",
    "# create dataset f(x,y) = exp(sin(pi*x)+y^2)\n",
    "f = lambda x: torch.exp(torch.sin(torch.pi*x[:,[0]]) + x[:,[1]]**2)\n",
    "dataset = create_dataset(f, n_var=2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch.backends.opt_einsum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m ourdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_input\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_input\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, input_size)\n\u001b[1;32m      7\u001b[0m ourdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_label\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mourdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_input\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#forward pass of the model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mplot() \u001b[38;5;66;03m#plots the model\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/kan/MultKAN.py:800\u001b[0m, in \u001b[0;36mMultKAN.forward\u001b[0;34m(self, x, singularity_avoiding, y_th)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macts\u001b[38;5;241m.\u001b[39mappend(x)  \u001b[38;5;66;03m# acts shape: (batch, width[l])\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth):\n\u001b[0;32m--> 800\u001b[0m     x_numerical, preacts, postacts_numerical, postspline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact_fun\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;66;03m#print(preacts, postacts_numerical, postspline)\u001b[39;00m\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbolic_enabled \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/kan/KANLayer.py:157\u001b[0m, in \u001b[0;36mKANLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    154\u001b[0m preacts \u001b[38;5;241m=\u001b[39m x[:,\u001b[38;5;28;01mNone\u001b[39;00m,:]\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mexpand(batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_dim)\n\u001b[1;32m    156\u001b[0m base \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_fun(x) \u001b[38;5;66;03m# (batch, in_dim)\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mcoef2curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m postspline \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    161\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_base[\u001b[38;5;28;01mNone\u001b[39;00m,:,:] \u001b[38;5;241m*\u001b[39m base[:,:,\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_sp[\u001b[38;5;28;01mNone\u001b[39;00m,:,:] \u001b[38;5;241m*\u001b[39m y\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/kan/spline.py:76\u001b[0m, in \u001b[0;36mcoef2curve\u001b[0;34m(x_eval, grid, coef, k, device)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03mconverting B-spline coefficients to B-spline curves. Evaluate x on B-spline curves (summing up B_batch results over B-spline basis).\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     75\u001b[0m b_splines \u001b[38;5;241m=\u001b[39m B_batch(x_eval, grid, k\u001b[38;5;241m=\u001b[39mk)\n\u001b[0;32m---> 76\u001b[0m y_eval \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mijk,jlk->ijl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_splines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_splines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_eval\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/functional.py:348\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meinsum\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    211\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"einsum(equation, *operands) -> Tensor\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \n\u001b[1;32m    213\u001b[0m \u001b[38;5;124;03m    Sums the product of the elements of the input :attr:`operands` along dimensions specified using a notation\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03m                [ 0.3311,  5.5201, -3.0356]])\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopt_einsum\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mopt_einsum\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;66;03m# This wrapper exists to support variadic args.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch.backends.opt_einsum'"
     ]
    }
   ],
   "source": [
    "#Our dataset\n",
    "data = OurData()\n",
    "ourdata = {}\n",
    "ourdata['train_input'] = data['train_input'].view(-1, input_size)\n",
    "ourdata['train_label'] = data['train_label']\n",
    "ourdata['test_input'] = data['test_input'].view(-1, input_size)\n",
    "ourdata['test_label'] = data['test_label']\n",
    "\n",
    "model(ourdata['train_input']) #forward pass of the model\n",
    "model.plot() #plots the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to train the model\n",
    "'''\n",
    "Training the model off the dataset\n",
    "- opt: optimization method (LBFGS)\n",
    "- steps: training steps\n",
    "- lamb: penalty parameter\n",
    "other parameters: lr = learning rate = 1, loss_fn = loss function = None\n",
    "'''\n",
    "#fits the model to the dataset\n",
    "'''\n",
    "model.fit(ourdata, opt=\"LBFGS\", steps=50, lamb=0.001) #values from the basic example in the documentation\n",
    "model.plot() #plots the model\n",
    "\n",
    "model = model.prune()\n",
    "model.plot()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch._subclasses.schema_check_mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mourdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/_tensor.py:523\u001b[0m, in \u001b[0;36m__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/_tensor_str.py:706\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/_python_dispatch.py:235\u001b[0m, in \u001b[0;36m_disable_current_modes\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch._subclasses.schema_check_mode'"
     ]
    }
   ],
   "source": [
    "print(ourdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch._subclasses.schema_check_mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/_tensor.py:523\u001b[0m, in \u001b[0;36m__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/_tensor_str.py:706\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/_python_dispatch.py:235\u001b[0m, in \u001b[0;36m_disable_current_modes\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch._subclasses.schema_check_mode'"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
